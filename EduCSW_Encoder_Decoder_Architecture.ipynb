{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub transformers\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STOXgc7D5Foi",
        "outputId": "3ff8bdad-5a12-4210-da56-486c78d0656e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `ruishichen_0314` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `ruishichen_0314`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n0Vmq-2mzxOn",
        "outputId": "b5047747-41b0-43bf-c6ce-70c9b5b1c1d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List, Tuple, Dict\n",
        "import spacy\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import ast\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8qXf_LC0Ktr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "4dd0cfdc-8ff5-4176-8633-4bf216943e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  instruction input                                             output\n",
              "0  保持健康的三个提示。        以下是保持健康的三个提示：\\n\\n1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游...\n",
              "1     三原色是什么？        三原色通常指的是红色、绿色和蓝色（RGB）。它们是通过加色混合原理创建色彩的三种基础颜色。在..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92fb2b01-2d0e-4905-a8b1-1827d12bd842\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>保持健康的三个提示。</td>\n",
              "      <td></td>\n",
              "      <td>以下是保持健康的三个提示：\\n\\n1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>三原色是什么？</td>\n",
              "      <td></td>\n",
              "      <td>三原色通常指的是红色、绿色和蓝色（RGB）。它们是通过加色混合原理创建色彩的三种基础颜色。在...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92fb2b01-2d0e-4905-a8b1-1827d12bd842')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92fb2b01-2d0e-4905-a8b1-1827d12bd842 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92fb2b01-2d0e-4905-a8b1-1827d12bd842');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-79999e2e-901f-4e49-b470-b563a515107e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79999e2e-901f-4e49-b470-b563a515107e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-79999e2e-901f-4e49-b470-b563a515107e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "a_sample",
              "summary": "{\n  \"name\": \"a_sample\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"\\u4f7f\\u7528\\u7ed9\\u5b9a\\u6570\\u636e\\u8ba1\\u7b97\\u4e2d\\u4f4d\\u6570\\u3002\",\n          \"\\u751f\\u6210\\u968f\\u673a\\u5355\\u8bcd\\u5217\\u8868\\u3002\",\n          \"\\u6982\\u8ff0\\u68ee\\u6797\\u780d\\u4f10\\u7684\\u540e\\u679c\\u3002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"\",\n          \"\\u8f93\\u5165\\uff1aTwitter\\uff0cInstagram\\uff0cTelegram\\u3002\",\n          \"\\u5c3d\\u7ba1\\u4eba\\u4eec\\u666e\\u904d\\u8ba4\\u4e3a\\u4e92\\u8054\\u7f51\\u4f7f\\u6211\\u4eec\\u80fd\\u591f\\u4e0e\\u4e16\\u754c\\u5404\\u5730\\u7684\\u4eba\\u8054\\u7cfb\\uff0c\\u4f46\\u4ecd\\u6709\\u4e00\\u4e9b\\u4eba\\u4e0d\\u719f\\u6089\\u5176\\u57fa\\u672c\\u529f\\u80fd\\uff0c\\u4e0d\\u7406\\u89e3\\u4e3a\\u4ec0\\u4e48\\u5b83\\u53d8\\u5f97\\u5982\\u6b64\\u666e\\u904d\\uff0c\\u6216\\u8005\\u5b83\\u7684\\u771f\\u6b63\\u80fd\\u529b\\u662f\\u4ec0\\u4e48\\u3002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"\\u4e2d\\u4f4d\\u6570\\u662f\\u6307\\u5728\\u4e00\\u7ec4\\u6570\\u636e\\u4e2d\\uff0c\\u8fd9\\u7ec4\\u6570\\u636e\\u4ece\\u5c0f\\u5230\\u5927\\u6392\\u5217\\u540e\\uff0c\\u4f4d\\u4e8e\\u4e2d\\u95f4\\u4f4d\\u7f6e\\u7684\\u6570\\u3002\\u5982\\u679c\\u6570\\u636e\\u7684\\u6570\\u91cf\\u4e3a\\u5947\\u6570\\uff0c\\u90a3\\u4e48\\u4e2d\\u4f4d\\u6570\\u5c31\\u662f\\u4e2d\\u95f4\\u90a3\\u4e2a\\u6570\\u3002\\u5982\\u679c\\u6570\\u636e\\u7684\\u6570\\u91cf\\u4e3a\\u5076\\u6570\\uff0c\\u90a3\\u4e48\\u4e2d\\u4f4d\\u6570\\u4e3a\\u4e2d\\u95f4\\u4e24\\u4e2a\\u6570\\u7684\\u5e73\\u5747\\u503c\\u3002\\n\\u5728\\u8fd9\\u4e2a\\u4f8b\\u5b50\\u4e2d\\uff0c\\u7ed9\\u5b9a\\u7684\\u6570\\u636e\\u96c6\\u662f[2, 3, 7, 8, 10]\\uff0c\\u5df2\\u7ecf\\u4ece\\u5c0f\\u5230\\u5927\\u6392\\u5217\\u3002 \\u6570\\u636e\\u6570\\u91cf\\u662f5\\uff0c\\u662f\\u4e00\\u4e2a\\u5947\\u6570\\uff0c\\u6240\\u4ee5\\u4e2d\\u4f4d\\u6570\\u5c31\\u662f\\u6b63\\u4e2d\\u95f4\\u7684\\u90a3\\u4e2a\\u6570\\uff0c\\u53737\\u3002\\u6240\\u4ee5\\u8fd9\\u7ec4\\u6570\\u636e\\u7684\\u4e2d\\u4f4d\\u6570\\u662f7\\u3002\",\n          \"[\\\"hippopotamus\\\", \\\"giraffe\\\", \\\"rhinoceros\\\", \\\"cheetah\\\", \\\"platypus\\\", \\\"parrot\\\", \\\"jellyfish\\\", \\\"octopus\\\", \\\"dolphin\\\", \\\"panther\\\"]\",\n          \"\\u68ee\\u6797\\u780d\\u4f10\\u662f\\u6307\\u5927\\u89c4\\u6a21\\u780d\\u4f10\\u68ee\\u6797\\u4ee5\\u83b7\\u53d6\\u6728\\u6750\\u6216\\u8005\\u5f00\\u8f9f\\u571f\\u5730\\u8fdb\\u884c\\u5176\\u4ed6\\u6d3b\\u52a8\\u3002\\u8fd9\\u4e00\\u884c\\u4e3a\\u4f1a\\u9020\\u6210\\u8bb8\\u591a\\u73af\\u5883\\u548c\\u793e\\u4f1a\\u540e\\u679c\\u3002\\n\\n\\u4ece\\u73af\\u5883\\u65b9\\u9762\\u6765\\u770b\\uff0c\\u68ee\\u6797\\u780d\\u4f10\\u4f1a\\u4f7f\\u5f97\\u571f\\u5730\\u6d41\\u5931\\u80a5\\u6c83\\u7684\\u8868\\u571f\\uff0c\\u5bfc\\u81f4\\u571f\\u58e4\\u6d41\\u5931\\u548c\\u5e72\\u65f1\\u3002\\u540c\\u65f6\\uff0c\\u68ee\\u6797\\u780d\\u4f10\\u4f1a\\u7834\\u574f\\u52a8\\u690d\\u7269\\u7684\\u6816\\u606f\\u5730\\uff0c\\u5a01\\u80c1\\u751f\\u7269\\u591a\\u6837\\u6027\\u3002\\u68ee\\u6797\\u7684\\u51cf\\u5c11\\u8fd8\\u4f1a\\u6539\\u53d8\\u6c14\\u5019\\u6a21\\u5f0f\\uff0c\\u5f15\\u53d1\\u5e72\\u65f1\\uff0c\\u6d2a\\u6c34\\u7b49\\u81ea\\u7136\\u707e\\u5bb3\\u3002\\n\\n\\u793e\\u4f1a\\u65b9\\u9762\\uff0c\\u68ee\\u6797\\u780d\\u4f10\\u4f1a\\u5f71\\u54cd\\u5230\\u5f53\\u5730\\u793e\\u533a\\u7684\\u7ecf\\u6d4e\\u548c\\u751f\\u6d3b\\u65b9\\u5f0f\\u3002\\u8bb8\\u591a\\u793e\\u533a\\u4f9d\\u8d56\\u68ee\\u6797\\u7684\\u8d44\\u6e90\\uff0c\\u5982\\u6728\\u6750\\uff0c\\u6c34\\u679c\\u548c\\u836f\\u6750\\uff0c\\u68ee\\u6797\\u780d\\u4f10\\u53ef\\u80fd\\u4f1a\\u7834\\u574f\\u4ed6\\u4eec\\u7684\\u751f\\u8ba1\\u3002\\u68ee\\u6797\\u780d\\u4f10\\u8fd8\\u53ef\\u80fd\\u5bfc\\u81f4\\u571f\\u5730\\u7ea0\\u7eb7\\u548c\\u51b2\\u7a81\\u3002\\n\\n\\u6b64\\u5916\\uff0c\\u68ee\\u6797\\u780d\\u4f10\\u8fd8\\u4f1a\\u5f71\\u54cd\\u5168\\u7403\\u6c14\\u5019\\u53d8\\u5316\\u3002\\u68ee\\u6797\\u662f\\u91cd\\u8981\\u7684\\u78b3\\u6c47\\uff0c\\u51cf\\u5c11\\u68ee\\u6797\\u4f1a\\u4f7f\\u5927\\u91cf\\u7684\\u4e8c\\u6c27\\u5316\\u78b3\\u91ca\\u653e\\u8fdb\\u5927\\u6c14\\u5c42\\uff0c\\u52a0\\u5267\\u5168\\u7403\\u53d8\\u6696\\u3002\\n\\nIn conclusion,\\u780d\\u4f10\\u68ee\\u6797\\u4f1a\\u5e26\\u6765\\u591a\\u79cd\\u73af\\u5883\\u548c\\u793e\\u4f1a\\u95ee\\u9898\\uff0c\\u4e3a\\u4e86\\u53ef\\u6301\\u7eed\\u53d1\\u5c55\\uff0c\\u5e94\\u5f53\\u91c7\\u53d6\\u63aa\\u65bd\\u63a7\\u5236\\u780d\\u4f10\\u884c\\u4e3a\\uff0c\\u4fdd\\u62a4\\u68ee\\u6797\\u3002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "csw_translated = load_dataset(\"RuishiCh0314/ASCEND-mixed-to-chinese-translation\")\n",
        "csw_aligned_df = pd.read_csv('/content/csw_aligned.csv')\n",
        "with open(\"data3_chi_complex_finalized.json\", 'rb') as f:\n",
        "    raw_data = f.read()\n",
        "    data = json.loads(raw_data.decode('utf-8-sig'))  # or try other encodings\n",
        "\n",
        "data3 = pd.DataFrame(data)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import MarianMTModel\n",
        "from transformers.modeling_outputs import BaseModelOutput\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import json\n",
        "import io\n",
        "\n",
        "a_sample = data3.iloc[:30].copy()\n",
        "a_sample.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAYIXYmu0RYR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import MarianMTModel, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CodeMixedGenerator(nn.Module):\n",
        "    def __init__(self, pretrained_model_name, device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.model = MarianMTModel.from_pretrained(pretrained_model_name).to(device)\n",
        "        self.copy_gate = nn.Linear(self.model.config.d_model, 1).to(device)\n",
        "        self.vocab_size = self.model.config.vocab_size\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # Ensure attention_mask is 2D\n",
        "        if attention_mask.dim() == 1:\n",
        "            attention_mask = attention_mask.unsqueeze(0)\n",
        "        elif attention_mask.dim() == 3:\n",
        "            attention_mask = attention_mask.squeeze(1)\n",
        "\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "            output_hidden_states=True,\n",
        "            return_dict=True\n",
        "        )\n",
        "\n",
        "        decoder_hidden_states = outputs.decoder_hidden_states[-1]\n",
        "        copy_scores = torch.sigmoid(self.copy_gate(decoder_hidden_states))\n",
        "\n",
        "        logits = outputs.logits\n",
        "        batch_size, seq_len, _ = logits.shape\n",
        "\n",
        "        copy_logits = torch.zeros_like(logits)\n",
        "        input_ids_expanded = input_ids.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "        copy_logits.scatter_(2, input_ids_expanded, 1.0)\n",
        "\n",
        "        combined_logits = (1 - copy_scores) * logits + copy_scores * copy_logits\n",
        "\n",
        "        outputs.logits = combined_logits\n",
        "        return outputs\n",
        "\n",
        "    def generate(self, input_ids, attention_mask):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            input_ids = input_ids.to(self.device)\n",
        "            attention_mask = attention_mask.to(self.device)\n",
        "\n",
        "            if input_ids.dim() == 1:\n",
        "                input_ids = input_ids.unsqueeze(0)\n",
        "            if attention_mask.dim() == 1:\n",
        "                attention_mask = attention_mask.unsqueeze(0)\n",
        "            elif attention_mask.dim() == 3:\n",
        "                attention_mask = attention_mask.squeeze(1)\n",
        "\n",
        "            outputs = self.model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=128,\n",
        "                num_beams=5,\n",
        "                no_repeat_ngram_size=2,\n",
        "                length_penalty=1.0,\n",
        "                early_stopping=True,\n",
        "                output_hidden_states=True,\n",
        "                return_dict_in_generate=True\n",
        "            )\n",
        "\n",
        "            return outputs.sequences\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, device, tokenizer):\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "    criterion = CodeMixingLoss(tokenizer)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience, patience_counter = 3, 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
        "        for batch in train_pbar:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask, labels)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            train_pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
        "        with torch.no_grad():\n",
        "            for batch in val_pbar:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask, labels)\n",
        "                loss = criterion(outputs.logits, labels)\n",
        "                val_loss += loss.item()\n",
        "                val_pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "            print(\"New best model saved!\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "    return model\n",
        "\n",
        "class CodeMixingLoss(nn.Module):\n",
        "    def __init__(self, tokenizer, alpha=0.5):\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.alpha = alpha\n",
        "        self.ce_loss = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        ce_loss = self.ce_loss(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "\n",
        "        # Calculate the ratio of Chinese to English tokens\n",
        "        chinese_mask = (labels >= self.tokenizer.vocab_size // 2).float()\n",
        "        mixing_ratio = chinese_mask.mean(dim=1)\n",
        "\n",
        "        # Penalize outputs that are too monolingual\n",
        "        mixing_loss = ((mixing_ratio - 0.5).abs() * 2).mean()\n",
        "\n",
        "        return ce_loss + self.alpha * mixing_loss\n",
        "\n",
        "\n",
        "    def generate(self, input_ids, attention_mask):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            input_ids = input_ids.to(self.device)\n",
        "            attention_mask = attention_mask.to(self.device)\n",
        "\n",
        "            if input_ids.dim() == 1:\n",
        "                input_ids = input_ids.unsqueeze(0)\n",
        "            if attention_mask.dim() == 1:\n",
        "                attention_mask = attention_mask.unsqueeze(0)\n",
        "\n",
        "            outputs = self.model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=128,\n",
        "                num_beams=5,\n",
        "                no_repeat_ngram_size=2,\n",
        "                length_penalty=1.0,\n",
        "                early_stopping=True,\n",
        "                output_hidden_states=True,\n",
        "                return_dict_in_generate=True\n",
        "            )\n",
        "\n",
        "            return outputs.sequences\n",
        "class TranslationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_length=128):\n",
        "        self.data = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        src_encoding = self.tokenizer(\n",
        "            item['transcription'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        tgt_encoding = self.tokenizer(\n",
        "            item['translation'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': src_encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': src_encoding['attention_mask'].squeeze(),\n",
        "            'labels': tgt_encoding['input_ids'].squeeze()\n",
        "        }\n",
        "\n",
        "class CombinedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, code_mixed_data, translation_data, tokenizer, max_length=128):\n",
        "        self.code_mixed_data = code_mixed_data\n",
        "        self.translation_data = translation_data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.total_length = len(code_mixed_data) + len(translation_data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < len(self.code_mixed_data):\n",
        "            item = self.code_mixed_data.iloc[idx]\n",
        "            src_text = item['instruction_zh']\n",
        "            tgt_text = item['code_mixed']\n",
        "        else:\n",
        "            idx = idx - len(self.code_mixed_data)\n",
        "            item = self.translation_data[idx]\n",
        "            src_text = item['transcription']\n",
        "            tgt_text = item['chinese_translation']\n",
        "\n",
        "        src_encoding = self.tokenizer(\n",
        "            src_text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        tgt_encoding = self.tokenizer(\n",
        "            tgt_text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': src_encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': src_encoding['attention_mask'].squeeze(),\n",
        "            'labels': tgt_encoding['input_ids'].squeeze()\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns39KHrk2Nay",
        "outputId": "01bfa208-5e14-4f98-e7fa-77c886b4193b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code mixed data size: 744\n",
            "Translation data size: 2739\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")\n",
        "model = CodeMixedGenerator(\"yl31/opus-mt-zh-en-finetuned-cs-instruction\", device)\n",
        "\n",
        "# Load datasets\n",
        "code_mixed_data = csw_aligned_df  # This should be your DataFrame\n",
        "translation_dataset = load_dataset(\"RuishiCh0314/ASCEND-mixed-to-chinese-translation\")\n",
        "translation_data = translation_dataset['train']\n",
        "\n",
        "print(\"Code mixed data size:\", len(code_mixed_data))\n",
        "print(\"Translation data size:\", len(translation_data))\n",
        "\n",
        "# Create combined dataset\n",
        "combined_data = CombinedDataset(code_mixed_data, translation_data, tokenizer)\n",
        "\n",
        "# Split combined dataset\n",
        "train_size = int(0.8 * len(combined_data))\n",
        "val_size = len(combined_data) - train_size\n",
        "train_data, val_data = random_split(combined_data, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CodeMixedGenerator(\"yl31/opus-mt-zh-en-finetuned-cs-instruction\", device)\n",
        "num_epochs = 10\n",
        "trained_model = train_model(model, train_loader, val_loader, num_epochs, device, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model.eval()\n",
        "\n",
        "def generate_code_mixed(input_text):\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to(device)\n",
        "    attention_mask = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_ids = trained_model.generate(input_ids, attention_mask)\n",
        "    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "# Apply the generation function to each row in the DataFrame"
      ],
      "metadata": {
        "id": "zAfybCUfIfVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csw_aligned_df_sample = csw_aligned_df.iloc[:30].copy()\n",
        "csw_aligned_df_sample['code_mixed'] = csw_aligned_df_sample['instruction_zh'].apply(generate_code_mixed)"
      ],
      "metadata": {
        "id": "XkJToGucIic1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csw_aligned_df_sample[['instruction_zh','code_mixed']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "6v8dVeQkRJvS",
        "outputId": "b613a1c2-26e5-4fa8-c25d-5d4cf23aa690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      instruction_zh                                  code_mixed\n",
              "0            什么是计算机？                                什么 computer?\n",
              "1     计算机的基本组成部分有哪些？       什么 是 computer? what's the principles?\n",
              "2    计算机硬件与软件的区别是什么？   计算机 techniques with 软件的 difference what ?\n",
              "3        什么是冯·诺依曼结构？                    什么 von nueman structure?\n",
              "4          什么是嵌入式系统？                       什么 是 engineer system?\n",
              "5          什么是计算机程序？                               什么 是 process?\n",
              "6           什么是操作系统？                      什么 是 operating system?\n",
              "7             什么是硬盘？                                  什么 是 dyke?\n",
              "8             什么是内存？                                  什么 是 ical?\n",
              "9             什么是外存？                                     什么 是 存?\n",
              "10         什么是二进制数制？                          什么 是 binal system?\n",
              "11   如何将十进制数转换为二进制数？  如何就 defencing numerals? 转换 binal numeries?\n",
              "12        什么是十六进制数制？                        什么 是 henthal system?\n",
              "13  如何将二进制数转换为十六进制数？   如何把 binal numerals? 转换 to 六 in numerics ?\n",
              "14       什么是ASCII编码？                             什么 ACSCII code?\n",
              "15     什么是Unicode编码？                            什么 unicode code?\n",
              "16          什么是字符编码？                         什么 是 chain encoder?\n",
              "17         什么是浮点数表示？                            什么 是 float qual?\n",
              "18         什么是定点数表示？                        什么 是 minal numerals?\n",
              "19            什么是补码？                           什么 是 calculation?\n",
              "20            什么是算法？                                什么 是 algory?\n",
              "21       算法的基本特征有哪些？        Algorithms? What are the basic 特征s ?\n",
              "22          什么是递归算法？                  什么 是 regression algorithm?\n",
              "23          什么是迭代算法？                      什么 是 dieter algorithm?\n",
              "24           什么是穷举法？                           什么 是 exploration?\n",
              "25          什么是贪心算法？                       什么 是 graft algorithm?\n",
              "26          什么是动态规划？                   什么 是 minoral programming?\n",
              "27          什么是二分查找？                          什么 是 big searning?\n",
              "28          什么是冒泡排序？                  什么 是 urinal blob? sorting?\n",
              "29          什么是快速排序？                              什么 快速 sorting?"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ed09b05-ec81-4293-a4db-bff0958131e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction_zh</th>\n",
              "      <th>code_mixed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>什么是计算机？</td>\n",
              "      <td>什么 computer?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>计算机的基本组成部分有哪些？</td>\n",
              "      <td>什么 是 computer? what's the principles?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>计算机硬件与软件的区别是什么？</td>\n",
              "      <td>计算机 techniques with 软件的 difference what ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>什么是冯·诺依曼结构？</td>\n",
              "      <td>什么 von nueman structure?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>什么是嵌入式系统？</td>\n",
              "      <td>什么 是 engineer system?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>什么是计算机程序？</td>\n",
              "      <td>什么 是 process?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>什么是操作系统？</td>\n",
              "      <td>什么 是 operating system?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>什么是硬盘？</td>\n",
              "      <td>什么 是 dyke?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>什么是内存？</td>\n",
              "      <td>什么 是 ical?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>什么是外存？</td>\n",
              "      <td>什么 是 存?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>什么是二进制数制？</td>\n",
              "      <td>什么 是 binal system?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>如何将十进制数转换为二进制数？</td>\n",
              "      <td>如何就 defencing numerals? 转换 binal numeries?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>什么是十六进制数制？</td>\n",
              "      <td>什么 是 henthal system?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>如何将二进制数转换为十六进制数？</td>\n",
              "      <td>如何把 binal numerals? 转换 to 六 in numerics ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>什么是ASCII编码？</td>\n",
              "      <td>什么 ACSCII code?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>什么是Unicode编码？</td>\n",
              "      <td>什么 unicode code?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>什么是字符编码？</td>\n",
              "      <td>什么 是 chain encoder?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>什么是浮点数表示？</td>\n",
              "      <td>什么 是 float qual?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>什么是定点数表示？</td>\n",
              "      <td>什么 是 minal numerals?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>什么是补码？</td>\n",
              "      <td>什么 是 calculation?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>什么是算法？</td>\n",
              "      <td>什么 是 algory?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>算法的基本特征有哪些？</td>\n",
              "      <td>Algorithms? What are the basic 特征s ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>什么是递归算法？</td>\n",
              "      <td>什么 是 regression algorithm?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>什么是迭代算法？</td>\n",
              "      <td>什么 是 dieter algorithm?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>什么是穷举法？</td>\n",
              "      <td>什么 是 exploration?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>什么是贪心算法？</td>\n",
              "      <td>什么 是 graft algorithm?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>什么是动态规划？</td>\n",
              "      <td>什么 是 minoral programming?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>什么是二分查找？</td>\n",
              "      <td>什么 是 big searning?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>什么是冒泡排序？</td>\n",
              "      <td>什么 是 urinal blob? sorting?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>什么是快速排序？</td>\n",
              "      <td>什么 快速 sorting?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ed09b05-ec81-4293-a4db-bff0958131e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ed09b05-ec81-4293-a4db-bff0958131e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ed09b05-ec81-4293-a4db-bff0958131e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d0c274e5-7042-4eec-beb1-81bd5cb52745\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d0c274e5-7042-4eec-beb1-81bd5cb52745')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d0c274e5-7042-4eec-beb1-81bd5cb52745 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"csw_aligned_df_sample[['instruction_zh','code_mixed']]\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"instruction_zh\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"\\u4ec0\\u4e48\\u662f\\u4e8c\\u5206\\u67e5\\u627e\\uff1f\",\n          \"\\u4ec0\\u4e48\\u662fUnicode\\u7f16\\u7801\\uff1f\",\n          \"\\u4ec0\\u4e48\\u662f\\u8fed\\u4ee3\\u7b97\\u6cd5\\uff1f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"code_mixed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"\\u4ec0\\u4e48 \\u662f big searning?\",\n          \"\\u4ec0\\u4e48 unicode code?\",\n          \"\\u4ec0\\u4e48 \\u662f dieter algorithm?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csw_aligned_df['code_mixed_generated'] = csw_aligned_df['instruction_zh'].apply(generate_code_mixed)"
      ],
      "metadata": {
        "id": "4VCBb2hlWxUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_indices_short = random.sample(range(len(csw_aligned_df)-200), 25)\n",
        "sample_indices_long = csw_aligned_df.iloc[675:700]\n",
        "short = csw_aligned_df.iloc[sample_indices_short]\n",
        "combined_df = pd.concat([short, sample_indices_long], axis=0).reset_index(drop=True)\n",
        "combined_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRirRnxagiH2",
        "outputId": "17c33e93-7a44-4481-8654-a31a232cc5f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50 entries, 0 to 49\n",
            "Data columns (total 8 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   instruction_zh        50 non-null     object \n",
            " 1   instruction_en        50 non-null     object \n",
            " 2   input_zh              0 non-null      float64\n",
            " 3   input_en              50 non-null     object \n",
            " 4   alignment_info        50 non-null     object \n",
            " 5   alignment_dict        50 non-null     object \n",
            " 6   code_mixed            50 non-null     object \n",
            " 7   code_mixed_generated  50 non-null     object \n",
            "dtypes: float64(1), object(7)\n",
            "memory usage: 3.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation: Qualitative & CMI"
      ],
      "metadata": {
        "id": "390UpapzcL9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "sample_indices = random.sample(range(len(csw_aligned_df)), 5)\n",
        "for i in sample_indices:\n",
        "    row = csw_aligned_df.iloc[i]\n",
        "    print(f\"\\nRow {i}:\")\n",
        "    print(f\"Chinese: {row['instruction_zh']}\")\n",
        "    print(f\"Code-mixed: {row['code_mixed']}\")\n",
        "    print(f\"Code-mixed_generated: {row['code_mixed_generated']}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeqU0d8BZcUD",
        "outputId": "aa549d73-d070-4030-f392-b694952c3812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Row 424:\n",
            "Chinese: 什么是数据可用性？\n",
            "Code-mixed: 什么 是 data availability?\n",
            "Code-mixed_generated: 什么 是 data application?\n",
            "--------------------------------------------------\n",
            "\n",
            "Row 697:\n",
            "Chinese: 在自然语言处理（NLP）中，如何通过文本摘要技术提取文档的关键信息？请描述其工作原理和关键技术。\n",
            "Code-mixed: 在 language processing （ nlp ）中，如何 through 文本摘要 technology? 提取 documents 的 key information technology? please describe 其工作原理 and technologies.\n",
            "Code-mixed_generated: 在 language processing ( nlp )中,如何通过文本 analysis technology? 取 the dagrication of the chains? please describe 其工作 principles and tey tyncs.\n",
            "--------------------------------------------------\n",
            "\n",
            "Row 267:\n",
            "Chinese: 什么是区块链的分布式账本？\n",
            "Code-mixed: 什么 block chain? for distributed account chain?\n",
            "Code-mixed_generated: 什么 是 block chain? in the different-packed challeng?\n",
            "--------------------------------------------------\n",
            "\n",
            "Row 57:\n",
            "Chinese: 什么是云计算？\n",
            "Code-mixed: 什么 云 computing?\n",
            "Code-mixed_generated: 什么 是 cloud calculation?\n",
            "--------------------------------------------------\n",
            "\n",
            "Row 445:\n",
            "Chinese: 什么是存储卷？\n",
            "Code-mixed: 什么 是 storage roll?\n",
            "Code-mixed_generated: 什么 是 storage?\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "\n",
        "class CMICalculator:\n",
        "    def __init__(self):\n",
        "        # Define regex patterns for different types of tokens\n",
        "        self.chinese_pattern = re.compile(r'[\\u4e00-\\u9fff]+')\n",
        "        self.english_pattern = re.compile(r'[a-zA-Z]+')\n",
        "\n",
        "    def tokenize(self, text: str) -> List[str]:\n",
        "        \"\"\"Split text into tokens while preserving Chinese characters\"\"\"\n",
        "        # First split by whitespace for English words\n",
        "        tokens = text.split()\n",
        "        processed_tokens = []\n",
        "\n",
        "        for token in tokens:\n",
        "            # If token contains Chinese characters, split them\n",
        "            if self.chinese_pattern.search(token):\n",
        "                # Split into individual Chinese characters\n",
        "                chinese_chars = list(token)\n",
        "                processed_tokens.extend(chinese_chars)\n",
        "            else:\n",
        "                processed_tokens.append(token)\n",
        "\n",
        "        return processed_tokens\n",
        "\n",
        "    def identify_language(self, token: str) -> str:\n",
        "        \"\"\"Identify the language of a token\"\"\"\n",
        "        if self.chinese_pattern.match(token):\n",
        "            return 'zh'\n",
        "        elif self.english_pattern.match(token):\n",
        "            return 'en'\n",
        "        else:\n",
        "            return 'other'\n",
        "\n",
        "    def calculate_cmi(self, text: str) -> Tuple[float, dict]:\n",
        "        \"\"\"Calculate Code-Mixing Index and language statistics\"\"\"\n",
        "        tokens = self.tokenize(text)\n",
        "\n",
        "        # Count tokens by language\n",
        "        language_counts = {'zh': 0, 'en': 0, 'other': 0}\n",
        "        for token in tokens:\n",
        "            lang = self.identify_language(token)\n",
        "            language_counts[lang] += 1\n",
        "\n",
        "        # Calculate total meaningful tokens (excluding 'other')\n",
        "        total_tokens = language_counts['zh'] + language_counts['en']\n",
        "\n",
        "        # Calculate switches between languages\n",
        "        switches = 0\n",
        "        prev_lang = None\n",
        "        for token in tokens:\n",
        "            curr_lang = self.identify_language(token)\n",
        "            if curr_lang != 'other':  # Skip non-linguistic tokens\n",
        "                if prev_lang and curr_lang != prev_lang:\n",
        "                    switches += 1\n",
        "                prev_lang = curr_lang\n",
        "\n",
        "        # Calculate CMI\n",
        "        if total_tokens > 0:\n",
        "            cmi = (switches / total_tokens) * 100\n",
        "        else:\n",
        "            cmi = 0.0\n",
        "\n",
        "        # Prepare detailed statistics\n",
        "        stats = {\n",
        "            'total_tokens': total_tokens,\n",
        "            'language_counts': language_counts,\n",
        "            'switches': switches,\n",
        "            'cmi': cmi\n",
        "        }\n",
        "\n",
        "        return cmi, stats\n",
        "\n",
        "def calculate_dataset_cmi(df: pd.DataFrame, text_column: str) -> pd.DataFrame:\n",
        "    \"\"\"Calculate CMI for an entire dataset\"\"\"\n",
        "    calculator = CMICalculator()\n",
        "\n",
        "    results = []\n",
        "    for idx, row in df.iterrows():\n",
        "        text = row[text_column]\n",
        "        cmi, stats = calculator.calculate_cmi(text)\n",
        "\n",
        "        result = {\n",
        "            'row_id': idx,\n",
        "            'cmi': cmi,\n",
        "            'total_tokens': stats['total_tokens'],\n",
        "            'chinese_tokens': stats['language_counts']['zh'],\n",
        "            'english_tokens': stats['language_counts']['en'],\n",
        "            'other_tokens': stats['language_counts']['other'],\n",
        "            'language_switches': stats['switches']\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "o7-p4PRVaJb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = calculate_dataset_cmi(csw_aligned_df, 'code_mixed_generated')\n",
        "np.mean(results_df['cmi'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS6hMvkcaa9j",
        "outputId": "61e11e9e-d080-4fa6-a7f6-0d45dc2dd47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.576600214861916"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_first_round = calculate_dataset_cmi(csw_aligned_df, 'code_mixed')\n",
        "np.mean(results_df_first_round['cmi'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29pvZZF7atsJ",
        "outputId": "cc57bf56-8005-4cb2-f05b-6b4e0249f127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.890539204475054"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}